# -*- coding: utf-8 -*-
"""final colab.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18WuEEyrlHA3pmN4ilTw_6BKW5yyvRXYq
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install lucifer-ml

import warnings
warnings.filterwarnings("ignore")
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
import seaborn as sns
import matplotlib.pyplot as plt
from luciferml.supervised.regression import Regression

df = pd.read_csv('/content/drive/MyDrive/S7/Data-Melbourne_F.csv',index_col =0)

atmospheric_values = [
    'Average Temperature',
    'Maximum temperature',
    'Minimum temperature',
    'Atmospheric pressure',
    'Average humidity',
    'Total rainfall',
    'Average visibility',
    'Average wind speed',
    'Maximum wind speed',
]

time = [
    'Year',
    'Month',
    'Day',
]

df.head()

df.describe().T.style.bar(
    subset=['mean'],
    color='#606ff2').background_gradient(
    subset=['std'], cmap='PuBu').background_gradient(subset=['50%'], cmap='PuBu')

from google.colab import drive
drive.mount('/content/drive')

df.isna().sum()

fig = px.histogram(x='year', data_frame=df, histfunc='count',
                   template='plotly_dark', color='year', title = 'Data Gathered Yearly')
fig.show()

fig = px.histogram(x='month', data_frame=df, histfunc='count',
                   template='plotly_dark', color='month', title = 'Data Gathered Monthly')
fig.show()

fig = px.histogram(x='day', data_frame=df, histfunc='count', template='plotly_dark', color='day', title = 'Data Gathered Daily')
fig.show()

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import seaborn as sns
import matplotlib.pyplot as plt
from scipy.stats import shapiro
from sklearn.ensemble import IsolationForest
from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score, f1_score
from sklearn.inspection import permutation_importance
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC, LinearSVC
from sklearn.pipeline import Pipeline, make_pipeline
from sklearn.preprocessing import Normalizer, StandardScaler
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, StackingClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score, f1_score
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import cross_val_score, cross_val_predict
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import make_scorer, f1_score

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

def show_distributions(columns: list, data: pd.DataFrame, nrows: int = 1, ncols: int = 3):
    # This function creates distribution subplots.
    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(15, 5))
    axes = axes.ravel()
    for index, column in enumerate(columns):
        sns.histplot(data[column], kde=True, ax=axes[index])
        axes[index].set_title(column)

        # Adjust layout
    plt.tight_layout()
    plt.show()

def show_boxplots(columns: list, data: pd.DataFrame, nrows: int = 3, ncols: int = 3):
    # This function creates box plot subplots.
    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(10, 15))
    axes = axes.ravel()
    for index, column in enumerate(columns):
        axes[index].boxplot(data[column])
        axes[index].set_title(column)

    plt.tight_layout()
    plt.show()

def normality_test(columns: list, data: pd.DataFrame):
    # Conducts Shapiro-Wilk test.
    for i in columns:
        results = shapiro(data[data[i].isna() == False][i])
        print(i, results.statistic)

def random_sample_imputation(df):
    # Random Sample Imputatuin
    cols_with_missing_values = df.columns[df.isna().any()].tolist()

    for var in cols_with_missing_values:

        random_sample_df = df[var].dropna().sample(df[var].isnull().sum(),
                                                      random_state=0)
        random_sample_df.index = df[
                df[var].isnull()].index

        df.loc[df[var].isnull(), var] = random_sample_df

    return df

def visualize_isolation_forest(columns: list, data: pd.DataFrame, contamination: list,nrows: int = 2, ncols: int = 3,):
    # Visualize resuls from different contamination values
    sns.set_style("darkgrid")
    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(15, 5))
    axes = axes.ravel()
    for index, i in enumerate(contamination):
        model = IsolationForest(contamination=i)  # Adjust the contamination parameter
        model.fit(data.to_numpy())
        sns.scatterplot(data = data[model.predict(data.to_numpy()) == -1], x = columns[0], y = columns[1], color='blue', label='Outlier', ax = axes[index])
        sns.scatterplot(data = data[model.predict(data.to_numpy()) == 1], x = columns[0], y = columns[1], color='red', label='Normal', ax = axes[index])
        axes[index].legend()
        axes[index].set_title(f"Contamination Value: {round(i,3)}")
    plt.show()

def remove_outliers(data: pd.DataFrame, contamination: int):
    # Apply Isolation Forest
    model = IsolationForest(contamination = contamination)
    model.fit(data.to_numpy())
    return data[model.predict(data.to_numpy()) == 1]

def roc_plot(models: list, X_test: pd.DataFrame, y_test: pd.DataFrame):
    # Create ROC plot for multiple models.]
    plt.figure(figsize=(20,10))
    ns_probs = [0 for _ in range(len(X_test))]
    ns_auc = roc_auc_score(y_test, ns_probs)
    ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)
    plt.plot(ns_fpr, ns_tpr, linestyle='--', label='Baseline')
    for model in models:
        lr_probs = model.predict_proba(X_test)
        lr_probs = lr_probs[:, 1]
        lr_auc = roc_auc_score(y_test, lr_probs)
        lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)
        plt.plot(lr_fpr, lr_tpr, marker='.', label = model["classifier"])

    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.legend()
    plt.show()

def forest_feature_importance(model,X_test):
    # Visualize Random Forest Feature Importance
    feature_names = list(X_test.columns)
    importances = model.feature_importances_
    std = np.std([tree.feature_importances_ for tree in model.estimators_], axis=0)
    forest_importances = pd.Series(importances, index=feature_names)

    fig, ax = plt.subplots()
    forest_importances.plot.bar(yerr=std, ax=ax)
    ax.set_title("Feature importances using MDI")
    ax.set_ylabel("Mean decrease in impurity")
    fig.tight_layout()

def forest_permutation_importance(model, X_test, y_test, n_repeats:int = 10):
    # Visualize Random Forest Permutation Importance
    feature_names = list(X_test.columns)
    importances = model.feature_importances_
    importances = model.feature_importances_
    std = np.std([tree.feature_importances_ for tree in model.estimators_], axis=0)
    result = permutation_importance(
        model, X_test.to_numpy(), y_test, n_repeats=n_repeats, random_state=42, n_jobs=2
    )
    forest_importances = pd.Series(importances, index = feature_names)
    fig, ax = plt.subplots()
    forest_importances.plot.bar(yerr=result.importances_std, ax=ax)
    ax.set_title("Feature importances using permutation on full model")
    ax.set_ylabel("Mean accuracy decrease")
    fig.tight_layout()
    plt.show()

data = pd.read_csv("/content/drive/MyDrive/s7 final colab/water_potability.csv")

data.head()

data.describe()

data.isna().sum()

sns.heatmap(data.corr(), annot = True,fmt='.1f')

show_distributions(data.columns[:-1], data,3,3)

normality_test(data.columns[:-1], data)

missing_columns = ["Sulfate", "Trihalomethanes", "ph"]
show_distributions(missing_columns, data)

for i in ["Sulfate", "Trihalomethanes", "ph"]:
    data_mean = data.fillna(data.mean())

show_distributions(missing_columns, data_mean)

data_random = random_sample_imputation(data)

show_distributions(missing_columns, data_random)

show_boxplots(data_random.columns[:-1], data_random)

contamination = np.arange(0.1, 0.6, 0.1)

visualize_isolation_forest(["ph", "Hardness"], data_random,contamination)

data_forest = remove_outliers(data_random, 0.3)

model = IsolationForest(contamination = 0.3)
model.fit(data_random.to_numpy())
data_random[model.predict(data_random.to_numpy()) == -1]
plt.figure(figsize= (20,10))
sns.scatterplot(data = data_random[model.predict(data_random.to_numpy()) == -1], x = "ph", y = "Solids", color = "red", label = "removed")
sns.scatterplot(data = data_random[model.predict(data_random.to_numpy()) == 1], x = "ph", y = "Solids", color = "blue", label = "kept")

# We can see that there is less outliers.
show_boxplots(data_forest.columns[:-1], data_forest)

data_forest.Potability.value_counts()

sm = SMOTE(random_state=42)

X, y = data_forest[data_forest.columns[:-1]], data_forest["Potability"]
X, y = sm.fit_resample(X, y)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)
models = [RandomForestClassifier(), LogisticRegression(), AdaBoostClassifier(), KNeighborsClassifier(), QuadraticDiscriminantAnalysis(), GaussianNB(), SVC(probability=True), DecisionTreeClassifier()]
pipelines = {}
for model in models:
    model_name = str(model.__class__).split(".")[-1].split("'")[0]
    pipe = Pipeline([
        ("scaler", StandardScaler()),  # Preprocessing step
        ("classifier", model)  # Classifier step
    ])
    pipelines[model_name] = pipe


for name,pipe in pipelines.items():
    print(f"Training {name}")
    scores = cross_val_score(pipe, X_train, y_train, cv = 5, scoring = "accuracy")
    print(f"Mean Score {scores.mean()} -- Std {scores.std()} -- Min {scores.min()} -- Max {scores.max()}")

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))
import pandas as pd

df= pd.read_csv("/content/drive/MyDrive/s7 final colab/water_potability.csv")

df.head()

df.info()

df['Potability']=df['Potability'].astype('category')

#create approve limit for each features based on data available in Google search
cols=df.columns[0:9].to_list()
min_val=[6.52,0,500,0,3,0,0,0,0]
max_val=[6.83,0,1000,4,250,400,2,80,5]
limit=pd.DataFrame(data=[min_val, max_val], columns=cols)

df.describe().T.style.background_gradient(subset=['mean','std','50%','count'], cmap='PuBu')

#Portability is 1 - means good for Human
df[df['Potability']==1].describe().T.style.background_gradient(subset=['mean','std','50%','count'], cmap='PuBu')

# Portability is 0 - means not good for Human
df[df['Potability']==0].describe().T.style.background_gradient(subset=['mean','std','50%','count'], cmap='RdBu')

df.isnull().sum()

df[df['Sulfate'].isnull()]
df[df['ph'].isnull()]
df[df['Trihalomethanes'].isnull()]

#Replace null values based on the group/sample mean
df['ph']=df['ph'].fillna(df.groupby(['Potability'])['ph'].transform('mean'))
df['Sulfate']=df['Sulfate'].fillna(df.groupby(['Potability'])['Sulfate'].transform('mean'))
df['Trihalomethanes']=df['Trihalomethanes'].fillna(df.groupby(['Potability'])['Trihalomethanes'].transform('mean'))

df.isna().sum()

#Import ploting libraries
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
colors = ['#06344d','#00b2ff']
sns.set(palette=colors, font='Serif', style='white', rc={'axes.facecolor':'#f1f1f1', 'figure.facecolor':'#f1f1f1'})
sns.palplot(colors)

#Lets check the Target features first
fig = plt.figure(figsize=(10,6))
ax=sns.countplot(data=df, x='Potability')
for i in ax.patches:
    ax.text(x=i.get_x()+i.get_width()/2, y=i.get_height()/7, s=f"{np.round(i.get_height()/len(df)*100,0)}%", ha='center', size=50, weight='bold', rotation=90, color='white')
plt.title("Potability Feature", size=20, weight='bold')
plt.annotate(text="Not safe for Human consumption", xytext=(0.5,1750),xy=(0.2,1250), arrowprops =dict(arrowstyle="->", color='black', connectionstyle="angle3,angleA=0,angleB=90"), color='black')
plt.annotate(text="Safe for Human consumption", xytext=(0.8,1500),xy=(1.2,1000), arrowprops =dict(arrowstyle="->", color='black',  connectionstyle="angle3,angleA=0,angleB=90"), color='black')

for name, pipe in pipelines.items():
    pipe.fit(X_train, y_train)
roc_plot(list(pipelines.values()), X_test, y_test)